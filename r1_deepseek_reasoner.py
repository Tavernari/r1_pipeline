"""
Title: ðŸ¤– R1 Deepseek Reasoner
Author: Victor Carvalho Tavernari
Date: 2025-01-23
Version: 0.0.1
License: MIT
Description:
    This pipeline give the agentic power to the model deepseek r1 reasoning model.
Requirements: openai==1.60.0, pydantic==2.10.5, typing-extensions==4.12.2, schemas==0.7.1, tavily-python==0.5.0, trafilatura==2.0.0, lxml_html_clean==0.4.1
"""

from pydantic import BaseModel, Field
from enum import Enum
from typing import List, Union, Generator, Iterator, Optional
from pydantic import BaseModel, Field, ConfigDict

from datetime import datetime
from openai import OpenAI
from tavily import TavilyClient
import subprocess
import os
import json
import urllib.request
import trafilatura


# Mark: Functions

from pydantic import BaseModel, Field
from typing import Optional, List

from pydantic import BaseModel, Field
from typing import Optional, List

class TextWebSearchRequest(BaseModel):
    """
    Model representing a text web search request with various customizable parameters.
    """
    keywords: str = Field(
        ...,
        description="The search query string containing the main terms or phrases to look up."
    )
    search_depth: Optional[str] = Field(
        default="basic",
        description=(
            "Determines the thoroughness of the search. "
            "Options are 'basic' for a standard search or 'advanced' for a more comprehensive search. "
            "Defaults to 'basic'."
        )
    )
    topic: Optional[str] = Field(
        default="general",
        description=(
            "Specifies the category of the search to utilize specialized search agents. "
            "Currently supported options are 'general' for a broad search or 'news' for current news articles. "
            "Defaults to 'general'."
        )
    )
    time_range: Optional[str] = Field(
        default=None,
        description=(
            "Filters search results based on their publication date relative to the current date. "
            "Accepted values are 'day' (past 24 hours), 'week' (past 7 days), 'month' (past 30 days), "
            "or 'year' (past 365 days). If set to None, no time-based filtering is applied. "
            "Defaults to None."
        )
    )
    # max_results: Optional[int] = Field(
    #     default=10,
    #     description=(
    #         "The maximum number of search results to return. "
    #         "Defaults to 10."
    #     )
    # )
    include_domains: Optional[List[str]] = Field(
        default=None,
        description=(
            "A list of specific domains to include in the search results. "
            "If provided, only results from these domains will be returned. "
            "Defaults to None, meaning no domain inclusion filtering."
        )
    )
    exclude_domains: Optional[List[str]] = Field(
        default=None,
        description=(
            "A list of specific domains to exclude from the search results. "
            "If provided, results from these domains will be omitted. "
            "Defaults to None, meaning no domain exclusion filtering."
        )
    )
    # include_answer: Optional[bool] = Field(
    #     default=False,
    #     description=(
    #         "Indicates whether to include a concise answer generated by a Large Language Model (LLM) "
    #         "based on the search results. Defaults to False."
    #     )
    # )
    # include_raw_content: Optional[bool] = Field(
    #     default=False,
    #     description=(
    #         "Specifies whether to include the cleaned and parsed HTML content of each search result. "
    #         "Defaults to False."
    #     )
    # )
    include_images: Optional[bool] = Field(
        default=False,
        description=(
            "Determines whether to include a list of images related to the search query in the response. "
            "Defaults to False."
        )
    )
    include_image_descriptions: Optional[bool] = Field(
        default=False,
        description=(
            "If 'include_images' is set to True, specifies whether to include descriptive text for each image. "
            "Defaults to False."
        )
    )


def execute_text_web_search_tool(text_web_search: TextWebSearchRequest, tvly_api_key:str, openai_client: OpenAI) -> dict:
    """
    Executa a ferramenta de pesquisa de texto na web com os parÃ¢metros fornecidos.
    """
    tavily_client = TavilyClient(api_key=tvly_api_key)
    response = tavily_client.search(
        query=text_web_search.keywords,
        search_depth=text_web_search.search_depth,
        topic=text_web_search.topic,
        time_range=text_web_search.time_range,
        max_results=3,
        include_domains=text_web_search.include_domains,
        exclude_domains=text_web_search.exclude_domains,
        include_answer=False,
        include_raw_content=True,
        include_images=text_web_search.include_images,
        include_image_descriptions=text_web_search.include_image_descriptions
    )

    results = response.get("results", [])

    for result in results:
        url = result.get("url", None)
        if url == None:
            continue

        extracted_content = execute_web_site_content_tool(WebSiteContent(url=url)) or None
        llm_response = openai_client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {
                    "role": "system",
                    "content": "You are a helpful assistant."
                },
                {
                    "role": "user",
                    "content": (
                        f"Given this website content: {extracted_content}\n"
                        f"Answer the term based on these keywords terms: {text_web_search.keywords}\n"
                    )
                }
            ],
            stream=False
        )

        result["answer_suggestion"] = llm_response.choices[0].message.content

    return response

class WebSiteContent(BaseModel):
    """
    Model representing a website content.
    """
    url: str = Field(
        ...,
        description="URL of the website."
    )

    model_config = ConfigDict(
        extra='forbid',
    )

def execute_web_site_content_tool(web_site_content: WebSiteContent) -> str:
    """
    Executes the web site content tool with the given parameters.
    """
    try:
        downloaded = trafilatura.fetch_url(web_site_content.url)
        if downloaded is None:
            return "Failed to download the webpage content."

        text = trafilatura.extract(downloaded)
        if text is None:
            return "Failed to extract the main content."

        return text
    except Exception as e:
        return str(e)

class CodeExecution(BaseModel):
    """
    Model representing a code execution request.
    """
    code: str = Field(
        ...,
        description="""
        The code to be executed in Python.
        To answer the step, you must add print statements to show the result of the code execution.
        """,
        strict=True,
    )

    model_config = ConfigDict(
        extra='forbid',
        strict=True,
    )

def execute_python_code(code: CodeExecution) -> (str, int):
    """
    Executes the given Python code and returns the output and return code.

    Args:
        code (str): The Python code to execute.

    Returns:
        Tuple[str, int]: A tuple containing the combined output and the return code.
    """
    try:
        result = subprocess.run(
            ["python", "-c", code.code],
            capture_output=True,
            text=True,
            check=True,
        )
        stdout = result.stdout.strip()
        stderr = result.stderr.strip()

        # if fails, return the error message
        if result.returncode != 0:
            return stderr

        return stdout
    except subprocess.CalledProcessError as e:
        stderr = e.stderr.strip()

        return stderr
    except Exception as e:
        return str(e)


# Mark: System Config

AVAILABLE_TOOLS = {
    "INTERNET_SEARCH": {
        "name": "Internet Search",
        "description": "Search the internet for the answer to the question.",
        "function": "internet_search",
        "input_description": TextWebSearchRequest.schema_json(),
    },
    "CODE_EXECUTER": {
        "name": "Code Executer",
        "description": "Execute code and return the result.",
        "function": "code_executer",
        "input_description": CodeExecution.schema_json(),
    },
    "SCRAPING": {
        "name": "Website Scraping",
        "description": "Scrape a specific website and return the content. If you need more information about the website, you must use the scraping tool.",
        "function": "scraping",
        "input_description": WebSiteContent.schema_json(),
    },
    "FINAL_ANSWER": {
        "name": "Final Answer",
        "description": "Return the final answer to the question, only if you are 100 percent sure about the answer",
        "function": "final_answer",
        "input_description": "The answer to the question.",
    },
}

def tag_generator(dict: dict) -> str:
    """
    Generate a tag from a tools dictionary
    Tag must start <function>{input_description}</function>
    """
    function = dict.get("function")
    return (
        f"\nFunction {dict.get('name')}: {dict.get('description')}\n"
        f"<{function}>{dict.get('input_description')}</{function}>\n"
    )

def available_tools_tags_generator(dict: dict) -> str:
    """
    Generate a tag from a tools dictionary
    Tag must start <function>{input_description}</function>
    """
    return "\n".join([tag_generator(dict) for dict in dict.values()])

SYSTEM_PROMPT = (
    "You should help the user to answer the question using the available tools.\n"
    "Now is: {now}\n"
    "Your ouput MUST be only a tag based on these available tools:\n"
    f"Available tools: {available_tools_tags_generator(AVAILABLE_TOOLS)}\n"
    "MANDATORY: \n"
    " - Only return one tag per interaction\n"
    " - If you have source of the information, you must link on the final answer\n"
    " - Output must be in markdown format\n"
    " - You must answer using the same language of the question\n"
    " - Always write the tag <confidence_level></confidence_level> at the end of the answer\n"
    " - You must only write a final answer when you has a high confidence level\n"
    " - You never assume any factor or information, you always check the fact of your answer\n"
    " - If the user doen't specify a date, you must search near to now: {now}\n"
)

# MARK: Pipeline

# Enum State
class State(str, Enum):
    """
    Enum for the state of the pipeline.
    """
    NEXT_STEP = "next_step"
    ERROR = "error"
    FINISHED = "finished"
    UNKNOWN = "unknown"

class StateResult(BaseModel):
    """
    Model representing the state of the pipeline.
    """
    state: State = Field(
        ...,
        description="The state of the pipeline."
    )
    message: str = Field(
        ...,
        description="The message to be sent to the user."
    )

class Pipeline:
    """
    Pipeline for processing user messages and interacting with the Deepseek R1 Reasoning model.

    This pipeline breaks down user input into steps, processes each step,
    and composes a final answer based on the steps and their results.
    """

    class Valves(BaseModel):
        DEEPSEEK_API_KEY: str = ""
        DEEPSEEK_BASE_URL: str = "https://api.deepseek.com"
        TVLY_API_KEY: str = ""
        MAX_DEPTH: int = 5
        pass

    def __init__(self):
        self.name = "ðŸ¤– R1 Deepseek Reasoner"
        self.valves = self.Valves(
            **{
                "DEEPSEEK_API_KEY": os.getenv("DEEPSEEK_API_KEY", "your-deepseek-api-key-here"),
                "DEEPSEEK_BASE_URL": os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com"),
                "TVLY_API_KEY": os.getenv("TVLY_API_KEY", "your-tvly-api-key-here")
            }
        )
        self.is_title_generation = False
        pass

    async def on_startup(self):
        # This function is called when the server is started.
        print(f"on_startup:{__name__}")
        self.client = OpenAI(
            api_key=self.valves.DEEPSEEK_API_KEY,
            base_url=self.valves.DEEPSEEK_BASE_URL or "https://api.deepseek.com"
        )
        pass

    async def on_shutdown(self):
        # This function is called when the server is stopped.
        print(f"on_shutdown:{__name__}")
        pass

    async def inlet(self, body: dict, user: dict) -> dict:
        print("inlet: %s", __name__)

        metadata = body.get("metadata", {})
        task = metadata.get("task", "")
        self.is_title_generation = task == "title_generation"

        return body

    def calculate_state(self, assistant_message: str) -> StateResult:
        # This function is called when the server is started.
        print(f"calculate_state:{__name__}")

        print("assistant_message", assistant_message)

        # Check if the assistant message contains the tag for the Internet Search tool.
        if "<internet_search>" in assistant_message:
            try:
                # extract content between <internet_search> and </internet_search>
                content = assistant_message.split("<internet_search>")[1].split("</internet_search>")[0]
                text_web_search = TextWebSearchRequest(**json.loads(content))

                if text_web_search.keywords == None or text_web_search.keywords == "":
                    return StateResult(
                        state=State.NEXT_STEP,
                        message="Please provide the keywords for the search."
                    )

                # Execute the text web search tool.
                result = execute_text_web_search_tool(text_web_search, self.valves.TVLY_API_KEY, self.client)
                # Return the result as a message.
                return StateResult(
                    state=State.NEXT_STEP,
                    message=f"<internet_search.result>{result}</internet_search.result>"  
                )
            except Exception as e:
                return StateResult(
                    state=State.ERROR,
                    message=f"Error parsing the text web search request: {e}"
                ) 
        
        if "<code_executer>" in assistant_message:
            try:
                # extract content between <code_executer> and </code_executer>
                content = assistant_message.split("<code_executer>")[1].split("</code_executer>")[0]
                code_execution = CodeExecution(**json.loads(content))
                result = execute_python_code(code_execution)
                # Return the result as a message.
                return StateResult(
                    state=State.NEXT_STEP,
                    message=f"<code_executer.result>{result}</code_executer.result>"
                )
            except Exception as e:
                return StateResult(
                    state=State.ERROR,
                    message=f"Error parsing the code executer request: {e}"
                )

        if "<scraping>" in assistant_message:
            try:
                # extract content between <scraping> and </scraping>
                content = assistant_message.split("<scraping>")[1].split("</scraping>")[0]
                web_site_content = WebSiteContent(**json.loads(content))
                result = execute_web_site_content_tool(web_site_content)
                # Return the result as a message.
                return StateResult(
                    state=State.NEXT_STEP,
                    message=f"<scraping.result>{result}</scraping.result>"
                )
            except Exception as e:
                return StateResult(
                    state=State.ERROR,
                    message=f"Error parsing the scraping request: {e}"
                )
        if "<final_answer>" in assistant_message:
            try:
                # extract content between <final_answer> and </final_answer>
                content = assistant_message.split("<final_answer>")[1].split("</final_answer>")[0]
                # remove <confidence_level> from the answer
                content = content.split("<confidence_level>")[0]
                # Return the result as a message.
                return StateResult(
                    state=State.FINISHED,
                    message=content
                )
            except Exception as e:
                return StateResult(
                    state=State.ERROR,
                    message=f"Error parsing the final answer request: {e}"
                )

        return StateResult(
            state=State.UNKNOWN,
            message=(
                "Unknown state. Please provide a valid command tag.\n\n"
                f"Available tools: {available_tools_tags_generator(AVAILABLE_TOOLS)}\n"
            )
        )

    def process_state(self, messages: List[dict], max_depth: int = None) -> str:
        """Recursively process state transitions and messages."""
        # Use the configured MAX_DEPTH from valves if max_depth is not provided
        max_depth = max_depth if max_depth is not None else self.valves.MAX_DEPTH
        if max_depth <= 0:
            return "Max recursion depth exceeded"

        # get all messages after the 0 (System) and concact all together and send as user

        response = self.client.chat.completions.create(
            model="deepseek-reasoner",
            messages=messages,
            stream=False
        )

        assistant_message = response.choices[0].message.content
        reasoning_content = response.choices[0].message.reasoning_content

        print((
            "\n\n------- Reasoning ------\n"
            f"{reasoning_content}"
            "------------------------\n\n\n"
        ))

        messages.append({"role": "assistant", "content": assistant_message})

        state_result = self.calculate_state(assistant_message)
        print(f"State Result: {state_result}")

        if state_result.state == State.FINISHED:
            return state_result.message
        else:
            messages.append({"role": "user", "content": state_result.message})
            return self.process_state(messages, max_depth - 1)

    def pipe(
        self, user_message: str, model_id: str, messages: List[dict], body: dict
    ) -> Union[str, Generator, Iterator]:
        """Main pipeline entry point with recursive state handling."""
        print(f"pipe:{__name__}")

        system_message = {
            "role": "system",
            "content": SYSTEM_PROMPT.replace("{now}", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        }

        messages = [system_message] + messages

        return self.process_state(messages).strip()